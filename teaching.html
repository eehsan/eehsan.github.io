<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Ehsan Shareghi's homepage">
    <meta name="author" content="Ehsan Shareghi">
    <meta name="keywords" content="ehsan, shareghi, homepage, phd, cv, curriculum vitae, resume, research, projects, publications, nlp, natural language processing, nonparametric bayesian, machine learning, compressed data structures, data science, bayesian inference, deep learning, university of cambridge, monash university">

    <link rel="stylesheet" type="text/css" href="styles/bootstrap.css">
    <link rel="stylesheet" type="text/css" href="styles/ie10-viewport-bug-workaround.css">
    <link rel="stylesheet" type="text/css" href="styles/font-awesome.css">
    <link rel="stylesheet" type="text/css" href="styles/bootstrap-social.css">
    <link rel="stylesheet" type="text/css" href="styles/index.css">

	<title>Ehsan Shareghi</title>
<style>
.p1 {
  font-family: "Papyrus";
}

.week-dropdown {
  margin-bottom: 10px;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.week-header {
  background-color: #f5f5f5;
  padding: 12px 15px;
  cursor: pointer;
  font-family: tahoma, sans-serif;
  font-weight: bold;
  display: flex;
  justify-content: space-between;
  align-items: center;
  transition: background-color 0.2s;
}

.week-header:hover {
  background-color: #e8e8e8;
}

.week-content {
  display: none;
  padding: 15px;
  background-color: #fff;
}

.week-content.active {
  display: block;
}

.week-content ul {
  margin: 0;
  padding-left: 20px;
}

.week-content li {
  margin-bottom: 8px;
}

.arrow {
  transition: transform 0.3s;
  font-size: 14px;
}

.arrow.rotated {
  transform: rotate(90deg);
}
</style>
</head>

<body>
	<nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" target="_self" href="https://eehsan.github.io/">Ehsan Shareghi</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a target="_self" href="publication.html">Publications</a></li>
	          <li><a target="_self" href="people.html">People</a></li>
            <li><a target="_self" href="teaching.html">Teaching</a></li>
            <li><a target="_self" href="mailto:ehsan.shareghi@monash.edu">Contact</a></li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="container">
	    <p>
		<strong><a class="quiet p1" href="https://www.monash.edu">Monash University</a>.</strong>
		<br>
		<p><span class="text-muted"><em>CE/Lecturer, Natural Language Processing (FIT5217, 2022-2025). Syllabus:</em></span></p>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 1 Introduction to Natural Language Processing</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content"></div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 2 Language Modelling</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>What is a language model?</li>
					<li>Context Length</li>
					<li>The Chain Rule of probability</li>
					<li>n-gram language models</li>
					<li>Data sparsity issues</li>
					<li>Smoothed n-grams
						<ul>
							<li>Add-k</li>
							<li>Kneser-Ney (not examinable)</li>
							<li>Stupid Backoff</li>
						</ul>
					</li>
					<li>Evaluating model performance</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 3 Sequence Labelling</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Word categories</li>
					<li>Part-of-Speech (POS) Tagging</li>
					<li>Other Sequence Labelling Problems</li>
					<li>Hidden Markov Model (HMM)</li>
					<li>Observation Likelihood</li>
					<li>Most Likely State Sequence</li>
					<li>Supervised Learning of HMM</li>
					<li>Evaluation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 4 Syntactic Parsing</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Syntax</li>
					<li>Syntactic Parsing</li>
					<li>CKY Parsing</li>
					<li>Limitations of Context Free Grammars
						<ul>
							<li>Statistical Parsing</li>
							<li>Probabilistic CKY Parsing</li>
						</ul>
					</li>
					<li>PCFG Training</li>
					<li>Limitations of PCFGs</li>
					<li>Treebanks</li>
					<li>Evaluating model performance</li>
					<li>Alternative Formalisms</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 5 Linear Text Classification</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Text classification</li>
					<li>Classification methods</li>
					<li>Naïve Bayes Model</li>
					<li>Logistic Regression Model</li>
					<li>Evaluation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 6 Neural Networks and Neural Language Models</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Introduction to Neural Networks</li>
					<li>The challenge of statistical language modelling</li>
					<li>Neural n-gram language models</li>
					<li>Recurrent language models</li>
					<li>A few key papers (not examinable)</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 7 Neural Machine Translation</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Machine Translation</li>
					<li>Decoding Algorithms</li>
					<li>Sequence-to-Sequence Models</li>
					<li>Attention Mechanism</li>
					<li>Evaluation of MT systems</li>
					<li>Examples of other Encoder-Decoder tasks</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 8 Distributional Semantics</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Meaning and Lexical Semantics</li>
					<li>Vector Semantics</li>
					<li>Count-based Distributed Representations (tf-id, PMI)</li>
					<li>Sparse vs. Dense Representation (SVD/PCA)</li>
					<li>Word Embeddings (Word2Vec, GloVe, fastText)</li>
					<li>Contextualized Word Embeddings (ELMo, BERT)</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 9 Transformers and Pretrained Models</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Transformers (in details)</li>
					<li>Pretrained Large Language Models
						<ul>
							<li>Encoders</li>
							<li>Decoders</li>
							<li>Encoder-Decoder</li>
						</ul>
					</li>
					<li>Parameter-efficient Finetuning Methods
						<ul>
							<li>Adapters</li>
							<li>Prefix-Tuning</li>
							<li>LoRA</li>
						</ul>
					</li>
					<li>Limitations, ethics, biases, environment</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 10 Neural Speech Recognition and Translation</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Speech Processing Tasks</li>
					<li>Automatic Speech Recognition
						<ul>
							<li>Model Design</li>
							<li>Evaluation Metrics</li>
						</ul>
					</li>
					<li>Speech Translation
						<ul>
							<li>Model Design</li>
							<li>Evaluation Metrics</li>
						</ul>
					</li>
					<li>Pre-trained Speech Transformers
						<ul>
							<li>Wav2vec 2</li>
							<li>Whisper Speech Encoder</li>
						</ul>
					</li>
					<li>SUPERB Evaluation Benchmark</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 11 Advanced Topics in Large Language Models (I)</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Prompting</li>
					<li>In-context zero- or few-shot prompting
						<ul>
							<li>Emergent in-context abilities</li>
							<li>Chain-of-thought Prompting</li>
						</ul>
					</li>
					<li>Instruction-Tuning Large Language Models</li>
					<li>Alignment with Human Feedback (PPO and DPO)
						<ul>
							<li>Policy Gradient</li>
							<li>Reward Model to Rank</li>
						</ul>
					</li>
					<li>System 1 and System 2 Modes of Reasoning</li>
					<li>Inference-Time Scaling</li>
					<li>Reasoning LLMs (GRPO, rule-based reward, distillation)</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 12 Advanced Topics in Large Language Models (II)</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>LLM Augmentations
						<ul>
							<li>Retrieval Augmented Generation (RAG)</li>
							<li>Tool-Augmentation</li>
							<li>Self-Correction</li>
						</ul>
					</li>
					<li>Language Agents
						<ul>
							<li>Training-free: ReAct, Reflexion, Critic, LATS</li>
							<li>Fine-tuned: FireAct, TORA, Eurus</li>
						</ul>
					</li>
					<li>Agentic Workflow</li>
					<li>Output and Process Reward Models and Verifiers</li>
				</ul>
			</div>
		</div>

		<p><span class="text-muted"><em>CE/Lecturer, Data Analysis for Semi-structured Data (FIT5212, 2022-2025). Syllabus:</em></span></p>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 1 Intro to semi-structured data</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content"></div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 2 Text representation</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Word and Document Representations (Count Vector, TF-IDF, LSA)</li>
					<li>Basic Embedding Models (Word2vec, GLoVe)</li>
					<li>Contextualized Embedding Models (ELMo, BERT)</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 3 Text classification</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Data Preparation</li>
					<li>Basic Classifier
						<ul>
							<li>Logistic Regression Model and Cross-Entropy Loss Function</li>
						</ul>
					</li>
					<li>Neural Network-based Classifier</li>
					<li>BERT-style Classification</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 4 Text clustering and matrix factorisation</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Clustering Examples</li>
					<li>Mixture Models</li>
					<li>Topic Models (LDA)</li>
					<li>Matrix Factorisation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 5 Text generation</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Neural Language Models</li>
					<li>Sequence-to-Sequence models</li>
					<li>Neural Machine Translation</li>
					<li>Attention mechanism</li>
					<li>Other language generation tasks</li>
					<li>Evaluation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 6 Pretrained language models</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Introduction to Transformers</li>
					<li>Pretrained Language Models
						<ul>
							<li>Pre-trained Encoder-Decoders (T5 and BART)</li>
							<li>Pre-trained Encoders (BERT family)</li>
							<li>Pre-trained Decoders (GPT family)</li>
						</ul>
					</li>
					<li>Finetuning Pretrained Language Models</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 7 Recommender systems (1)</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Introduction to recommender systems</li>
					<li>Various Recommender Systems in Real-Life Applications</li>
					<li>Content Based Recommendation Systems</li>
					<li>Collaborative Filtering Algorithms</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 8 Recommender systems (2)</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Matrix Factorisation for Recommender Systems</li>
					<li>Neural Collaborative Filtering</li>
					<li>Neural Matrix Factorisation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 9 Graph clustering</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Graph Basics</li>
					<li>K-means Graph Clustering</li>
					<li>Spectral Clustering</li>
					<li>Graph Clustering Evaluation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 10 Graph representation learning</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Network Embedding Principle</li>
					<li>Random Walk Based Approaches</li>
					<li>Matrix Factorization Approaches</li>
					<li>Evaluation</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 11 Graph Neural Networks</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Disadvantages of shallow embedding for graph data</li>
					<li>Connections of graph neural networks to traditional deep learning</li>
					<li>Basic idea of graph neural networks</li>
					<li>Graph Convolutional Network (GCN)</li>
					<li>GraphSage Network (GraphSage)</li>
					<li>Graph Attention Network (GAT)</li>
					<li>Application of graph neural networks</li>
				</ul>
			</div>
		</div>

		<div class="week-dropdown">
			<div class="week-header" onclick="toggleWeek(this)">
				<span>Week 12 Knowledge Graphs and Text</span>
				<span class="arrow">▶</span>
			</div>
			<div class="week-content">
				<ul>
					<li>Knowledge Graph construction</li>
					<li>Examples of Knowledge Graphs</li>
					<li>Knowledge-intensive tasks</li>
					<li>Infusing external knowledge into text models</li>
				</ul>
			</div>
		</div>

	    <p><strong><a class="quiet p1" href="https://www.ucl.ac.uk/">UCL</a>.</strong><br>
			<span class="text-muted">
				<em>Co-lecturer, Applied Machine Learning II (ELEC0135, 2020)</em>.<br>
	            <em>Module Lead, Emerging Topics in Integrated Machine Learning Systems (ELEC0139, 2020)</em>.
	        </span>
	    </p>
		<p><strong><a class="quiet p1" href="https://www.cam.ac.uk/">University of Cambridge</a>.</strong><br>
			<span class="text-muted">
				<em>Lecturer, Quantitative Methods in Analyzing Linguistic Data (QMALD, 2019)</em>.<br>
				<em>Guest Lecturer, Computational Linguistics (LI18, 2019)</em>.
			</span>
		</p>

	</div>

    <script src="styles/jquery.js"></script>
    <script>window.jQuery || document.write('<script src="bootstrap/assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="styles/bootstrap.js"></script>
    <script src="styles/ie10-viewport-bug-workaround.js"></script>

	<script>
	function toggleWeek(header) {
		const content = header.nextElementSibling;
		const arrow = header.querySelector('.arrow');
		
		content.classList.toggle('active');
		arrow.classList.toggle('rotated');
	}
	</script>

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115849498-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());
	  gtag('config', 'UA-115849498-1');
	</script>
</body>
</html>
